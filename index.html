<!DOCTYPE html>
<html>



<title>Siddharth Mitra</title>



<meta name="viewport" content="width=device-width, initial-scale=1">

<head>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-145445228-1"></script>
    <script>
     window.dataLayer = window.dataLayer || [];
     function gtag(){dataLayer.push(arguments);}
     gtag('js', new Date());

     gtag('config', 'UA-145445228-1');
    </script>
</head>

<body>

  
  
<div style="padding: 20px;">
<h1>Siddharth Mitra</h1>

<p><img src="content/profile.jpg" height="200px"/></p>

<p style="max-width: 900px;">
  I am a PhD student at Yale University in the Department of Computer Science where I am lucky to be advised by <a href="http://www.cs.yale.edu/homes/wibisono/" target="_blank">Andre Wibisono</a>. 
  </p>
  
 <p style="max-width: 900px;">
My research focuses on the design and analysis of algorithms for sampling and optimization.
</p>

 <p style="max-width: 900px;">
Prior to this, I was an undergraduate and masters student at the Chennai Mathematical Institute as well as a visiting student at the Indian Institute of Science, Bangalore. During this time, I worked with <a href="https://ece.iisc.ac.in/~aditya/index.html" target="_blank">Aditya Gopalan</a>, <a href="https://ece.iisc.ac.in/~htyagi/" target="_blank">Himanshu Tyagi</a>, and <a href="https://www.cmi.ac.in/~kv/" target="_blank">KV Subrahmanyam</a>.</p>

<p style="max-width: 900px;">
I can be reached at <tt> siddharth.mitra &lt;at&gt; yale &lt;dot&gt; edu</tt>.
</p>

<p style="max-width: 900px;">
My <a href="http://scholar.google.com/citations?hl=en&user=nbrC-JMAAAAJ" target="_blank">Google Scholar</a>.
</p>
    
</div>



<div style="padding: 20px;">
<h2>Research</h2>



 <b>On the Mixing Time of Unadjusted Hamiltonian Monte Carlo in KL Divergence and Rényi Divergence via One-shot Couplings</b> <br>
 (α-β) Nawaf Bou-Rabee, Siddharth Mitra, and Andre Wibisono<br>
    Preliminary version at <a href="https://sites.google.com/view/dynafrontneurips25" target="_blank">DynaFront 2025</a>.<br><br>


 <b>Characterizing Dependence of Samples along the Langevin Dynamics and Algorithms via Contraction of Φ-Mutual Information</b> <a href="https://arxiv.org/abs/2402.17067" target="_blank">[arXiv]</a><br>
 (α-β) Jiaming Liang, Siddharth Mitra, and Andre Wibisono<br>
    COLT 2025.<br><br>
 


    
 <b>On the Convergence of Min-Max Langevin Dynamics and Algorithm</b> <a href="https://arxiv.org/abs/2412.20471" target="_blank">[arXiv]</a><br>
 (α-β) Yang Cai, Siddharth Mitra, Xiuyuan Wang, and Andre Wibisono<br>
    COLT 2025.<br><br>
    
    

<b>Fast Convergence of Φ-Divergence Along the Unadjusted Langevin Algorithm and Proximal Sampler</b> <a href="https://arxiv.org/abs/2410.10699" target="_blank">[arXiv]</a><br>
(α-β) Siddharth Mitra and Andre Wibisono<br>
ALT 2025.<br><br>


 


  <b>Langevin Thompson Sampling with Logarithmic Communication: Bandits and Reinforcement Learning</b> <a href="https://arxiv.org/abs/2306.08803" target="_blank">[arXiv]</a><br>
 (α-β) Amin Karbasi, Nikki Kuang, Yian Ma, and Siddharth Mitra<br>
 ICML 2023.<br><br>


  <b>Submodular + Concave</b> <a href="https://arxiv.org/abs/2106.04769" target="_blank">[arXiv]</a><br>
 Siddharth Mitra, Moran Feldman, and Amin Karbasi<br>
 NeurIPS 2021.<br><br>
 

 <b>On Adaptivity in Information-constrained Online Learning</b> <a href="https://arxiv.org/abs/1910.08805" target="_blank">[arXiv]</a><br>
 Siddharth Mitra and Aditya Gopalan<br>
 AAAI 2020. Preliminary version at <a href="https://opt-ml.org/" target="_blank">OPT 2019</a> <a href="https://drive.google.com/file/d/1gFa_DaXDdSvde43lmNGSSWdYLbL6VcLW/view?usp=sharing" target="_blank">[OPT Poster]</a>.


</div>

<br><br>
  
</html>
